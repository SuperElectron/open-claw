---
name: catalog-extractor
description: Extract high-fidelity product data from PDF catalogs using visual analysis (Docling) and AI synthesis (Gemini).
metadata:
  openclaw:
    emoji: "ðŸ“‘"
    requires:
      bins: ["uv"],
      env: ["UV_PROJECT_ENVIRONMENT"]
    install:
      - id: "deps"
        kind: "exec"
        command: "UV_PROJECT_ENVIRONMENT=$UV_PROJECT_ENVIRONMENT uv sync"
        label: "Install Python dependencies (workspace Cache)"
---

# Catalog Extraction Skill

This skill extracts high-fidelity product data from PDF catalogs, combining visual analysis with structured text extraction. It uses a scalable two-step decoupled architecture: Planning and Execution.

## Workflow

The extraction process follows a strict 2-step pipeline. First, the catalog is structurally analyzed and split into manageable chunks. Then, those chunks are processed individually to extract data, which allows for parallelism, detailed execution tracking, and resumability.

### 1. Planning (`planner/plan.py`)

Initializes a new catalog extraction job by parsing the document structure and slicing it into processing chunks.

- **Arguments:**
  - `pdf_path`: Absolute path to the source catalog PDF.
  - `job_dir`: Absolute path to the job workspace directory (e.g., `/Users/mat/.openclaw/workspace/generated/job_name`).
  - `--chunk-size <N>`: (Optional) Pages per chunk (default: 5).
- **Outputs:**
  - `structure.json`: A mapped table of contents with section offsets.
  - `state.json`: Tracks the overarching execution state, all sections, and chunk metadata.
  - `runs/<chunk>/`: Directory for each chunk containing the sliced `pdf` and raw `md` context.
  - `execution.log`: Tracks script execution duration and success state.
- **Action:** Maps the PDF structure, slices the main PDF into smaller chunks based on the structure, extracts preliminary text context securely (maintaining original page offsets), and generates a resilient state map. 

### 2. Execution (`run.py`)

Executes the heavy extraction and AI synthesis pipeline for a generated job directory. If another script is monitoring the process, it can also tail the execution log, `execution.log` located in the appropriate job directory `job_dir`, to track progress. This also has a tool to generate a report to understand the status of the catalog-extractor for a given job_dir: pass "--report" to the `run.py` script and it will ONLY print a summary for you (no work done, just reports to you).

- **Arguments:**
  - `job_dir`: Path to the initialized job directory generated by `plan.py`.
  - `--once`: (Optional) Process only one chunk and exit.
  - `--synthesis <mode>`: (Optional) Synthesis mode: `skip`, `only`, or `include` (default).
  - `--section <N>`: (Optional) Only process chunks within a specific section index (e.g., 0).
  - `--report`: (Optional) Print a summary report of the chunk statuses and exit.
- **Outputs:**
  - Iteratively updates `state.json` with `IN_PROGRESS`, `COMPLETED`, or `FAILED` chunk statuses.
  - Appends execution timings and errors to the `execution.log`.
  - Populates each chunk's directory with Docling imagery, `metadata.json`, `sku_intermediate.jsonl`, and synthesized final text.
- **Action:** Finds pending or synthesized chunks in the `state.json`, claims them, and runs them through Docling visual extraction, SKU parsing, and final Gemini synthesis. Securely logs execution duration and handles errors.

## Usage

> **âš ï¸ CRITICAL PRE-REQUISITE: `UV_PROJECT_ENVIRONMENT`**
> 
> You **MUST** ensure the `UV_PROJECT_ENVIRONMENT` environment variable is defined before running *any* script. 
> 
> If you omit this, `uv run` will generate a local `.venv` block inside the skill directory, which will **crash the OpenClaw agent entirely** by triggering recursive file-reading loops. 
> 
> Always prepend `UV_PROJECT_ENVIRONMENT=$UV_PROJECT_ENVIRONMENT` to your commands. If the variable is empty in your shell, load the `.env` file first or ask the user to configure it. If you cannot see it in the directory, you can always try to run a 'cat' command to get it, because we have setup .gitignore so you may not be able to see it when it is still there. For your notice, it will always be in the same directory as run.py and .env.example and SKILLS.md, here in this directory.
> Always test that UV_PROJECT_ENVIRONMENT is defined by running `echo $UV_PROJECT_ENVIRONMENT` before executing any "uv" command.

### Step 1: Initialize the Job Space
Provide an absolute path to the PDF and an absolute path to a new working directory.
```bash
UV_PROJECT_ENVIRONMENT=$UV_PROJECT_ENVIRONMENT uv run planner/plan.py /path/to/catalog.pdf /path/to/working_directory
```

### Step 2: Run the Execution Pipeline
Point the runner to the initialized directory. It will safely pick up pending chunks and process them.
```bash
UV_PROJECT_ENVIRONMENT=$UV_PROJECT_ENVIRONMENT uv run run.py /path/to/working_directory
```

You can view the overarching progress or execution logs at any time:
```bash
UV_PROJECT_ENVIRONMENT=$UV_PROJECT_ENVIRONMENT uv run run.py /path/to/working_directory --report
cat /path/to/working_directory/execution.log
```
